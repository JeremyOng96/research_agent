{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e89b57d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import aisuite as ai\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from classification.classification_models.vit import ClassificationModel, ModelConfig\n",
    "from classification.classification_models.vit import ImageWoofDataset\n",
    "from classification.classification_metrics.metrics import ClassificationMetrics\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import json\n",
    "\n",
    "from utils import extract_improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea2da39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<improvement>Mixup</improvement>\n",
      "<improvement>CutMix</improvement>\n",
      "<improvement>RandAugment</improvement>\n",
      "<improvement>AutoAugment</improvement>\n",
      "<improvement>Canny edge detection</improvement>\n",
      "<improvement>Sobel filter concatenation</improvement>\n",
      "<improvement>Gabor filter concatenation</improvement>\n",
      "<improvement>Histogram equalization</improvement>\n",
      "<improvement>Test time augmentation</improvement>\n",
      "<improvement>ImageNet pretraining</improvement>\n",
      "<improvement>Local binary patterns</improvement>\n",
      "<improvement>Laplacian filter concatenation</improvement>\n",
      "<improvement>Color jitter</improvement>\n",
      "<improvement>Erasing</improvement>\n",
      "<improvement>HOG feature concatenation</improvement>\n"
     ]
    }
   ],
   "source": [
    "client = ai.Client()\n",
    "statistics = json.load(open(\"statistics.json\"))\n",
    "system_prompt = f\"\"\"\n",
    "        You are an experienced computer vision practitioner. \n",
    "        You are given a set of statistics and a user prompt. \n",
    "        You need to analyze the statistics and recommend a set of changes to the user prompt to improve the model's performance.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "I have a model that is trained on the ImageWoof dataset.\n",
    "The model is a TinyNet model.\n",
    "The model is trained for 10 epochs.\n",
    "The model is trained with a learning rate of 0.001.\n",
    "The model is trained with a weight decay of 0.01.\n",
    "The model is trained with a batch size of 2.\n",
    "The model is trained with a num_workers of 4.\n",
    "\n",
    "The results are as follows:\n",
    "{statistics}\n",
    "\n",
    "I want to improve the model's performance.\n",
    "What changes can I make besides the hyperparameters\n",
    "such as data centric approaches or concatenating traditional computer vision methods such as edge detection methods\n",
    "along the channels of the model as input to improve the model's performance?\n",
    "\n",
    "I want you to give me a list of changes that I can make to the model to improve its performance where the improvements should \n",
    "be enclosed in <improvement> and </improvement> tags without any punctuations, explanations, adjectives, just the name of the changes.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"ollama:gemini-3-flash-preview\",\n",
    "    messages=messages,\n",
    "    max_tokens=1000,\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d20b3da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apply Mixup and CutMix data augmentation', 'Concatenate Canny edge detection maps as an additional input channel', 'Initialize the model with ImageNet pretrained weights', 'Apply RandAugment transformation pipeline', 'Incorporate Sobel filter gradients along the channel dimension', 'Increase input image resolution to capture finer spatial details', 'Apply Test Time Augmentation during inference', 'Concatenate Local Binary Patterns features to the input image', 'Implement Gabor filter banks as fixed preprocessing layers', 'Utilize Fourier Transform magnitude components as auxiliary inputs', 'Perform data cleaning to remove mislabeled or noisy images in the training set', 'Apply color space conversion such as Lab or YCrCb and concatenate with RGB channels', 'Incorporate Histogram of Oriented Gradients as additional feature maps', 'Use AutoAugment specifically tuned for ImageNet style datasets', 'Apply Gaussian blurring or bilateral filtering as a noise reduction preprocessing step']\n"
     ]
    }
   ],
   "source": [
    "improvement_list = extract_improvements(response.choices[0].message.content)\n",
    "print(improvement_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ac9de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_agent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
