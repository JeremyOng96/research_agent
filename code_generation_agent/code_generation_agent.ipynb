{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "043c9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import aisuite as ai\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "# from classification.classification_models.vit import ClassificationModel, ModelConfig\n",
    "# from classification.classification_models.vit import ImageWoofDataset\n",
    "# from classification.classification_metrics.metrics import ClassificationMetrics\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import json\n",
    "import re\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36beb172",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeGenerationAgent:\n",
    "    def __init__(self, model_name: str, file_type: str = \"python\"):\n",
    "        self.client = ai.Client()\n",
    "        self.model_name = model_name\n",
    "        self.installed_packages = [line.strip() for line in open(\"../requirements.txt\", \"r\").readlines()]\n",
    "        self.system_prompt = f\"\"\"\n",
    "        You are an expert computer vision engineer.\n",
    "        You are given a user prompt and a file type: {file_type}.\n",
    "        The file packages you have access to are as follows: \n",
    "        {self.installed_packages}\n",
    "        You need to generate a code based on the instruction, and the packages you have access to.\n",
    "        The code should be enclosed in <improvement_code> and </improvement_code> tags\n",
    "        \"\"\"\n",
    "\n",
    "    def generate_code(self, improvement_prompt: str, project_context: str) -> str: \n",
    "        \"\"\"\n",
    "        Generate code on the improvement prompt.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        You are tasked to write a code to implement the following improvement: {improvement_prompt}.\n",
    "        This code is expected to be used in PyTorch / Lightning collate_fn to process the batch.\n",
    "        The code should be enclosed in <improvement_code> and </improvement_code> tags.\n",
    "        \n",
    "        The project context is as follows:\n",
    "        {project_context}\n",
    "\n",
    "        Please provide:\n",
    "        1. Complete, runnable code with proper imports.\n",
    "        2. Clear documentation and type hints.\n",
    "        3. Integration instructions.\n",
    "\n",
    "        <improvement_code> YOUR CODE HERE </improvement_code>\n",
    "        <integration_instructions> YOUR INTEGRATION INSTRUCTIONS HERE </integration_instructions>\n",
    "        \"\"\"\n",
    "        file_name = improvement_prompt.replace(\" \", \"_\").lower()\n",
    "        path = Path(f\"../classification/improvements/\")\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        results = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=messages,\n",
    "            temperature=0.0,\n",
    "            max_tokens=4000,\n",
    "        )\n",
    "\n",
    "        success, message = self.save_generated_code(results.choices[0].message.content, file_name, path)\n",
    "\n",
    "    def parse_code(self, content: str, tag: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Parse code from XML-like tags with better error handling\n",
    "        \n",
    "        Args:\n",
    "            content: Full LLM response\n",
    "            tag: Tag name (e.g., 'improvement_code', 'integration_instructions')\n",
    "        \n",
    "        Returns:\n",
    "            Extracted code or None if not found\n",
    "        \"\"\"\n",
    "        # Use DOTALL flag to match across newlines\n",
    "        pattern = f\"<{tag}>(.*?)</{tag}>\"\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        \n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        \n",
    "        # Fallback: try to find markdown code blocks\n",
    "        code_block_pattern = r\"\\n(.*?)\\n```\"\n",
    "        match = re.search(code_block_pattern, content, re.DOTALL)\n",
    "        \n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def save_generated_code(\n",
    "        self,\n",
    "        response_content: str, \n",
    "        file_name: str, \n",
    "        path: str = \".\",\n",
    "        save_instructions: bool = True\n",
    "    ) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Save generated code and optionally integration instructions\n",
    "        \n",
    "        Returns:\n",
    "            (success, message)\n",
    "        \"\"\"\n",
    "        # Parse code\n",
    "        improvement_code = self.parse_code(response_content, \"improvement_code\")\n",
    "        \n",
    "        if not improvement_code:\n",
    "            return False, \"‚ùå Failed to parse improvement code from response\"\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        Path(path).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save the main code file\n",
    "        code_file = Path(path) / f\"{file_name}.py\"\n",
    "        try:\n",
    "            with open(code_file, \"w\") as f:\n",
    "                f.write(improvement_code)\n",
    "            print(f\"‚úÖ Code saved to: {code_file}\")\n",
    "        except Exception as e:\n",
    "            return False, f\"‚ùå Failed to save code: {e}\"\n",
    "        \n",
    "        # Save integration instructions if present\n",
    "        if save_instructions:\n",
    "            integration_instructions = self.parse_code(response_content, \"integration_instructions\")\n",
    "            \n",
    "            if integration_instructions:\n",
    "                instructions_file = Path(path) / f\"{file_name}_INSTRUCTIONS.md\"\n",
    "                try:\n",
    "                    with open(instructions_file, \"w\") as f:\n",
    "                        f.write(integration_instructions)\n",
    "                    print(f\"üìÑ Instructions saved to: {instructions_file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Warning: Failed to save instructions: {e}\")\n",
    "        \n",
    "        # Also save the raw response for debugging\n",
    "        raw_file = Path(path) / f\"{file_name}.py\"\n",
    "        try:\n",
    "            with open(raw_file, \"w\") as f:\n",
    "                f.write(response_content)\n",
    "            print(f\"üíæ Raw response saved to: {raw_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Warning: Failed to save raw response: {e}\")\n",
    "        \n",
    "        return True, f\"Successfully saved {file_name}.py\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd8cc744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mixup', 'CutMix', 'RandAugment', 'AutoAugment', 'Canny edge detection', 'Sobel filter concatenation', 'Gabor filter concatenation', 'Histogram equalization', 'Test time augmentation', 'ImageNet pretraining', 'Local binary patterns', 'Laplacian filter concatenation', 'Color jitter', 'Erasing', 'HOG feature concatenation']\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "import re\n",
    "improvement_string = f\"\"\"\n",
    "<improvement>Mixup</improvement>\n",
    "<improvement>CutMix</improvement>\n",
    "<improvement>RandAugment</improvement>\n",
    "<improvement>AutoAugment</improvement>\n",
    "<improvement>Canny edge detection</improvement>\n",
    "<improvement>Sobel filter concatenation</improvement>\n",
    "<improvement>Gabor filter concatenation</improvement>\n",
    "<improvement>Histogram equalization</improvement>\n",
    "<improvement>Test time augmentation</improvement>\n",
    "<improvement>ImageNet pretraining</improvement>\n",
    "<improvement>Local binary patterns</improvement>\n",
    "<improvement>Laplacian filter concatenation</improvement>\n",
    "<improvement>Color jitter</improvement>\n",
    "<improvement>Erasing</improvement>\n",
    "<improvement>HOG feature concatenation</improvement>\n",
    "\n",
    "\"\"\"\n",
    "improvement_list = re.findall(r'<improvement>(.*?)</improvement>', improvement_string)\n",
    "print(improvement_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb254cbf",
   "metadata": {},
   "source": [
    "# Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ec09393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Code saved to: ../classification/improvements/mixup.py\n",
      "üìÑ Instructions saved to: ../classification/improvements/mixup_INSTRUCTIONS.md\n",
      "üíæ Raw response saved to: ../classification/improvements/mixup.py\n"
     ]
    }
   ],
   "source": [
    "coding_agent = CodeGenerationAgent(model_name=\"ollama:gemini-3-flash-preview\", file_type=\"python\")\n",
    "results = coding_agent.generate_code(improvement_prompt=\"Mixup\", project_context=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bb78e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(f\"../code_generation_agent/classification/improvements/mixup.py\")\n",
    "path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0856a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_agent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
